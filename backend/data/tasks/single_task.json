{
  "taskInfo": {
    "name": "Single Response Evaluation",
    "description": "Evaluate the quality of individual AI responses",
    "instructions": "Read the response and rate various aspects of its quality."
  },
  "dataset": "single_test.jsonl",
  "results": "single_results.jsonl",
  "presentation": {
    "type": "single",
    "displayType": "standard"
  },
  "feedback": {
    "clarity": {
      "type": "numeric",
      "label": "Clarity",
      "description": "Rate how clear and understandable the response is",
      "min": 1,
      "max": 5
    },
    "accuracy": {
      "type": "numeric",
      "label": "Accuracy",
      "description": "Rate how accurate the information is",
      "min": 1,
      "max": 5
    },
    "issues": {
      "type": "multiselect",
      "label": "Issues",
      "description": "Select any issues present in the response",
      "options": [
        {
          "label": "Grammar",
          "value": "grammar"
        },
        {
          "label": "Factual errors",
          "value": "factual_errors"
        },
        {
          "label": "Unclear explanation",
          "value": "unclear_explanation"
        },
        {
          "label": "Off-topic",
          "value": "off_topic"
        }
      ]
    }
  }
}